# Fichier : Makefile

# Variables
ENV_NAME=venv
PYTHON=$(ENV_NAME)/bin/python
PIP=$(ENV_NAME)/bin/pip
DATA=churn-bigml-80.csv
MODEL=churn_model.joblib
IMAGE_NAME=rayen_nom_4ds10_mlops
DOCKERHUB_USER=ton_nom_dutilisateur_dockerhub

.PHONY: install format lint security prepare train evaluate test mlflow-server run-api docker-build docker-run docker-push docker-all monitoring-start monitoring-stop clean clean-mlflow

# 1. CrÃ©er et activer l'environnement virtuel, installer les dÃ©pendances
install:
	@echo "ğŸ“¦ CrÃ©ation de l'environnement virtuel et installation des dÃ©pendances..."
	python3 -m venv $(ENV_NAME)
	$(PIP) install --upgrade pip
	$(PIP) install -r requirements.txt

# 2. Formatage automatique (black)
format: install
	@echo "ğŸ¨ Formatage du code avec Black..."
	$(PYTHON) -m black .

# 3. VÃ©rification qualitÃ© du code (flake8 + pylint)
lint: install
	@echo "ğŸ” Analyse du code avec flake8 et pylint..."
	$(PYTHON) -m flake8 main.py model_pipeline.py app.py
	$(PYTHON) -m pylint main.py model_pipeline.py app.py

# 4. SÃ©curitÃ© (bandit)
security: install
	@echo "ğŸ” VÃ©rification de la sÃ©curitÃ© du code avec Bandit..."
	$(PYTHON) -m bandit -r .

# 5. PrÃ©parer les donnÃ©es
prepare: install
	@echo "ğŸ§ª PrÃ©paration des donnÃ©es..."
	. $(ENV_NAME)/bin/activate && python main.py --data $(DATA) --prepare

# 6. EntraÃ®ner le modÃ¨le
train: install
	@echo "ğŸ§  EntraÃ®nement complet du modÃ¨le..."
	. $(ENV_NAME)/bin/activate && python main.py --data $(DATA) --train --evaluate --save $(MODEL)

# 7. Ã‰valuer le modÃ¨le chargÃ©
evaluate: install
	@echo "ğŸ“ˆ Ã‰valuation du modÃ¨le sauvegardÃ©..."
	. $(ENV_NAME)/bin/activate && python main.py --data $(DATA) --load --model $(MODEL)

# 8. Tests unitaires avec pytest
test: install
	@echo "ğŸ§ª ExÃ©cution des tests unitaires..."
	. $(ENV_NAME)/bin/activate && pytest tests/

# 9. Lancer l'interface MLflow
mlflow-server: install
	@echo "ğŸ“Š Lancement de l'interface MLflow sur http://localhost:5000..."
	. $(ENV_NAME)/bin/activate && mlflow ui --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host 0.0.0.0 --port 5000

# 10. Lancer l'API FastAPI
run-api: install
	@echo "ğŸš€ Lancement de l'API FastAPI sur http://127.0.0.1:8000/docs..."
	. $(ENV_NAME)/bin/activate && uvicorn app:app --reload --host 0.0.0.0 --port 8000

# 11. Construire l'image Docker
docker-build:
	@echo "ğŸ³ Construction de l'image Docker..."
	docker build -t $(IMAGE_NAME) .

# 12. ExÃ©cuter le conteneur Docker
docker-run:
	@echo "ğŸš¢ ExÃ©cution du conteneur Docker..."
	docker run -p 8000:8000 --name fastapi_container $(IMAGE_NAME)

# 13. Pousser l'image sur Docker Hub
docker-push:
	@echo "â˜ï¸ Push de l'image sur Docker Hub..."
	docker tag $(IMAGE_NAME) $(DOCKERHUB_USER)/$(IMAGE_NAME):latest
	docker push $(DOCKERHUB_USER)/$(IMAGE_NAME):latest

# 14. Lancer Elasticsearch et Kibana
monitoring-start:
	@echo "ğŸ” Lancement de la stack Elasticsearch et Kibana..."
	docker-compose up -d

# 15. ArrÃªter Elasticsearch et Kibana
monitoring-stop:
	@echo "ğŸ›‘ ArrÃªt de la stack Elasticsearch et Kibana..."
	docker-compose down

# 16. TÃ¢che complÃ¨te pour Docker
docker-all: docker-build docker-run docker-push

# 17. ExÃ©cution complÃ¨te (sans Docker)
all: install format lint security prepare train evaluate test mlflow-server

# 18. Nettoyage partiel (MLflow)
clean-mlflow:
	@echo "ğŸ§¹ Nettoyage des fichiers MLflow..."
	rm -rf mlruns mlflow.db

# 19. Nettoyage complet
clean: clean-mlflow
	@echo "ğŸ§¹ Nettoyage des fichiers gÃ©nÃ©rÃ©s..."
	rm -rf $(MODEL) $(ENV_NAME) __pycache__ *.pyc

# Ouvrir le front
open-frontend:
	@echo "ğŸŒ Ouverture du frontend..."
	wslview http://127.0.0.1:8000/static/index.html
